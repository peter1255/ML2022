{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Lasso regression exercise ",
   "metadata": {
    "cell_id": "3879109ca6ab4b91badaa6a1126a0e03",
    "tags": [],
    "is_collapsed": false,
    "deepnote_app_coordinates": {
     "x": 0,
     "y": 12,
     "w": 12,
     "h": 5
    },
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "markdown",
   "source": "a.) First we create our training data and testing data. Varying $\\lambda$ from 0 to 0.04, we fit the Lasso regression to the training data.",
   "metadata": {
    "cell_id": "f2b4a1e83e474c90996d2ca71f2f0d11",
    "tags": [],
    "deepnote_app_coordinates": {
     "x": 0,
     "y": 18,
     "w": 12,
     "h": 5
    },
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.71875
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "9a6e2183-01aa-42a6-8003-907507d9824e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f2d2e8fa",
    "execution_start": 1650312414283,
    "execution_millis": 4137,
    "deepnote_app_coordinates": {
     "x": 0,
     "y": null,
     "w": 12,
     "h": 5
    },
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1403,
    "deepnote_output_heights": [
     null,
     21.1875,
     282
    ]
   },
   "source": "# python\nimport numpy as np\nfrom sklearn.linear_model import Lasso \nimport matplotlib.pyplot as plt\nnp.random.seed(0)\nN_fold = 10\nN_test = 500\nN_train = 1000\nN = N_test + N_train\n\n# Specify feature dimensions of X and Y\nX_dim = 20\nY_dim = 10\nX = np . random . randn (N , X_dim )\n\n# Only have 10 non - zero entries in beta ,\nnnz = 10\nbeta = np . zeros (( X_dim * Y_dim ))\nnnz_idx = np . random . choice ( X_dim * Y_dim , nnz , replace = False )\nbeta [ nnz_idx ] = np . random . randn ( nnz ) * 2\nbeta = beta . reshape ( X_dim , Y_dim )\nY = X @ beta + np . random . rand (N , Y_dim )\n\n# Split training and testing set\nX_test = X[:N_test,:]\nY_test = Y[:N_test,:]\nX_train = X[N_test:,]\nY_train = Y[N_test:,]\n\nlams = np.linspace(0,0.04,41)\n\ndef MSE(y1,y2):\n    err = np.mean(np.square(y1 - y2))\n    return err\n\nmis = np.zeros_like(lams)\ni = 0\n\nfor ll in lams:\n    model = Lasso(ll)\n    model.fit(X_train, Y_train)\n    yhat = model.predict(X_train)\n    errop = MSE(yhat, Y_train)\n    mis[i] = errop\n    i = i + 1\n\n\n",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": "/shared-libs/python3.7/py-core/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.024e+01, tolerance: 8.381e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.162e+01, tolerance: 2.591e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.871e+01, tolerance: 4.390e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.272e+01, tolerance: 8.695e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.958e+01, tolerance: 8.014e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.174e+01, tolerance: 1.289e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.069e+01, tolerance: 3.452e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.872e+01, tolerance: 9.073e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.179e+01, tolerance: 8.576e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.055e+01, tolerance: 8.247e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "plt.plot(lams, mis)\nplt.xlabel('$\\lambda$')\nplt.ylabel('MSE')\nplt.title('Lasso regression error on training data')",
   "metadata": {
    "cell_id": "96b333c95561486c91be7aca00818453",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8f43bf0b",
    "execution_start": 1650312418534,
    "execution_millis": 689,
    "deepnote_app_coordinates": {
     "x": 0,
     "y": 30,
     "w": 12,
     "h": 5
    },
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 485.1875,
    "deepnote_output_heights": [
     21.1875,
     282
    ]
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "Text(0.5, 1.0, 'Lasso regression error on training data')"
     },
     "metadata": {}
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light",
      "image/png": {
       "width": 404,
       "height": 280
      }
     },
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": "The figure above shows the MSE of the Lasso regression on the training data. As we can see, the Lasso regression has the lowest MSE for small $\\lambda$. Because we are evaluate the error directly on the training data, the error is going to be lowest when the weights are allowed to be as large as they need to.",
   "metadata": {
    "cell_id": "d168ad37d550463ab372d5ee0c51a71d",
    "tags": [],
    "deepnote_app_coordinates": {
     "x": 0,
     "y": 24,
     "w": 12,
     "h": 5
    },
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 97.515625
   }
  },
  {
   "cell_type": "markdown",
   "source": "b.) Next we perform cross validation by partitioning the training data into 10 equally sized folds. Each iteration we leave one of the folds out as a validation set and train on the other 9 sets. Then we take the average of the testing error on each validation set when we compure the validation error. We repeat the process for $\\lambda$ varying from 0 to 0.04. ",
   "metadata": {
    "cell_id": "539154f13cda45d9b3e731081716d195",
    "tags": [],
    "deepnote_app_coordinates": {
     "x": 0,
     "y": 36,
     "w": 12,
     "h": 5
    },
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 97.515625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "d94f94cb3284446b8e62ae7919971ba4",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4959095c",
    "execution_start": 1650312419271,
    "execution_millis": 11967,
    "deepnote_app_coordinates": {
     "x": 0,
     "y": 6,
     "w": 12,
     "h": 5
    },
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1223,
    "deepnote_output_heights": [
     21.1875,
     21.1875,
     282
    ]
   },
   "source": "bin_size = int(N_train / N_fold)\nvalid_err = np.zeros_like(lams)\ntesties = np.zeros_like(lams)\ni = 0\n\nX_test = X[:N_test]\nY_test = Y[:N_test]\nX_train = X[N_test:]\nY_train = Y[N_test:]\n\nfor ll in lams:\n    running_ave = 0\n    running_ave2 = 0\n    for ex in range(N_fold):\n        test_x = X_train[ex*bin_size:(ex+1)*bin_size]\n        test_y = Y_train[ex*bin_size:(ex+1)*bin_size]\n        train_x = np.delete(X_train, range(ex*bin_size,(ex+1)*bin_size), 0)\n        train_y = np.delete(Y_train, range(ex*bin_size,(ex+1)*bin_size), 0)\n        model = Lasso(ll)\n        model.fit(train_x,train_y)\n        yhat = model.predict(test_x)\n        yhat2 = model.predict(X_test)\n        running_ave = running_ave + MSE(yhat, test_y)\n        running_ave2 = running_ave2 + MSE(yhat2, Y_test)\n    \n    valid_err[i] = running_ave / 9\n    testies[i] = running_ave2 / 9\n    i = i+1 \n\n",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "text": "/shared-libs/python3.7/py-core/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.631e+01, tolerance: 7.582e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.707e+01, tolerance: 2.297e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.434e+01, tolerance: 3.931e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+01, tolerance: 7.696e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.631e+01, tolerance: 7.353e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.840e+01, tolerance: 1.140e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.626e+01, tolerance: 3.050e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.455e+01, tolerance: 8.326e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.738e+01, tolerance: 7.725e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.630e+01, tolerance: 7.422e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py-core/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.653e+01, tolerance: 7.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.729e+01, tolerance: 2.303e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.466e+01, tolerance: 3.883e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.848e+01, tolerance: 7.839e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.575e+01, tolerance: 7.267e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.687e+01, tolerance: 1.157e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.655e+01, tolerance: 3.137e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.430e+01, tolerance: 8.303e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.745e+01, tolerance: 7.663e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.646e+01, tolerance: 7.414e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py-core/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.601e+01, tolerance: 7.504e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.748e+01, tolerance: 2.342e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.481e+01, tolerance: 3.867e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+01, tolerance: 7.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.500e+01, tolerance: 7.095e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.763e+01, tolerance: 1.169e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.721e+01, tolerance: 3.065e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.443e+01, tolerance: 8.128e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.724e+01, tolerance: 7.671e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.607e+01, tolerance: 7.368e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py-core/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.575e+01, tolerance: 7.495e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.753e+01, tolerance: 2.365e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.469e+01, tolerance: 3.931e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.830e+01, tolerance: 7.800e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.483e+01, tolerance: 7.095e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.747e+01, tolerance: 1.145e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.658e+01, tolerance: 3.105e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.520e+01, tolerance: 8.080e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.751e+01, tolerance: 7.718e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.680e+01, tolerance: 7.507e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py-core/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.627e+01, tolerance: 7.558e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.785e+01, tolerance: 2.299e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.490e+01, tolerance: 3.902e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.856e+01, tolerance: 7.874e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.549e+01, tolerance: 7.187e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.783e+01, tolerance: 1.161e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.623e+01, tolerance: 3.127e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.537e+01, tolerance: 8.120e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.744e+01, tolerance: 7.667e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.653e+01, tolerance: 7.438e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py-core/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.596e+01, tolerance: 7.458e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.779e+01, tolerance: 2.378e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.514e+01, tolerance: 4.053e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.866e+01, tolerance: 7.920e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.540e+01, tolerance: 7.195e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.783e+01, tolerance: 1.190e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.658e+01, tolerance: 3.140e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.495e+01, tolerance: 8.364e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.781e+01, tolerance: 7.784e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.649e+01, tolerance: 7.446e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py-core/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.626e+01, tolerance: 7.576e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.724e+01, tolerance: 2.333e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.504e+01, tolerance: 3.875e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.864e+01, tolerance: 7.846e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.597e+01, tolerance: 7.292e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+01, tolerance: 1.165e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.649e+01, tolerance: 3.100e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.459e+01, tolerance: 8.022e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.673e+01, tolerance: 7.553e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.653e+01, tolerance: 7.433e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py-core/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.592e+01, tolerance: 7.510e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.700e+01, tolerance: 2.331e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.435e+01, tolerance: 3.936e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.817e+01, tolerance: 7.793e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.533e+01, tolerance: 7.183e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.761e+01, tolerance: 1.154e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.607e+01, tolerance: 3.117e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.501e+01, tolerance: 8.176e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.816e+01, tolerance: 7.875e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.657e+01, tolerance: 7.439e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py-core/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.659e+01, tolerance: 7.617e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.719e+01, tolerance: 2.373e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.449e+01, tolerance: 4.064e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.889e+01, tolerance: 7.907e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.587e+01, tolerance: 7.276e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.708e+01, tolerance: 1.163e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.686e+01, tolerance: 3.174e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.432e+01, tolerance: 7.997e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.763e+01, tolerance: 7.752e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.673e+01, tolerance: 7.482e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py-core/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.563e+01, tolerance: 7.442e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.725e+01, tolerance: 2.296e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.498e+01, tolerance: 4.057e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.824e+01, tolerance: 7.800e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.540e+01, tolerance: 7.176e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.724e+01, tolerance: 1.162e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.661e+01, tolerance: 3.043e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.482e+01, tolerance: 8.136e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.766e+01, tolerance: 7.761e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.559e+01, tolerance: 7.269e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "plt.figure()\nplt.plot(lams, testies,label='Test error')\nplt.plot(lams, valid_err,label='Validation error')\nplt.legend(fontsize=16)\nplt.xlabel('$\\lambda$')\nplt.ylabel('MSE')\nplt.title('Lasso regression error' )",
   "metadata": {
    "cell_id": "2d093e45f82d4dea97791055ce4c1521",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f985e2fd",
    "execution_start": 1650312431260,
    "execution_millis": 958,
    "deepnote_app_coordinates": {
     "x": 0,
     "y": 42,
     "w": 12,
     "h": 5
    },
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 539,
    "deepnote_output_heights": [
     21,
     282
    ]
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 4,
     "data": {
      "text/plain": "Text(0.5, 1.0, 'Lasso regression error')"
     },
     "metadata": {}
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light",
      "image/png": {
       "width": 404,
       "height": 280
      }
     },
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": "The figure above shows both the validation error and the error computed on the testing set as a function of $\\lambda$. As we can see, the test error is lowest for $\\lambda = 0.013$. When $\\lambda$ is too low, the data is overfitted to the training data and the variance is large. When $\\lambda$ is too high, the data is underfitted and the variance is low. Lasso regression gives the best performance for $\\lambda$ in the lower-middle part of this range. Moreover we can see that the validation error is lower than the test error because we are ultimately testing on part of the set that we are training on when we take the average over multiple folds, whereas the test set is new data that the model has never seen before. The test data is also much larger than the validation data which increases the possibility for error.",
   "metadata": {
    "cell_id": "52fc4f59031b43b09017f6106a2d97f9",
    "tags": [],
    "deepnote_app_coordinates": {
     "x": 0,
     "y": 48,
     "w": 12,
     "h": 5
    },
    "owner_user_id": "083d6339-abaa-49e1-a2c1-a7e63e498030",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 343.375
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=9361817e-01e6-4be3-8ec2-744b514329ea' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {},
  "deepnote_notebook_id": "e9f6bee7-7dbe-43bc-8bd2-9e2688242f86",
  "deepnote_execution_queue": [],
  "deepnote_app_layout": "article"
 }
}
